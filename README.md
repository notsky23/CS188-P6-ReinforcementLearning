# CS188-P6-ReinforcementLearning

Disclaimer: This is my attempt at the CS188 coursework 2 from the University of California, Berkeley.<br>

Project Site: https://inst.eecs.berkeley.edu/~cs188/sp22/projects/.<br><br>

## What is this project about?<br>

This project is a practice with different techniques for reinforcement learning agents.<br>

In this project, we will create a PacMan AI agent that uses reinforcement learning algorithms and techniques, and train them for specific objectives (ex. winning the game/getting the highest score).<br>

The agent will start out knowing nothing, but as we train and fine-tune (ex. adapting weights for rewards) the agent, it learns to get better at achieving the desired result.<br><br>

## Results:<br>

You can read more about this module and deliverables at this site: https://inst.eecs.berkeley.edu/~cs188/sp22/project6/<br>

Here are the results I got.<br>

The code is included in this repo.<br><br>

### Warmup with MDP(Markov Decision Process)
![image](https://user-images.githubusercontent.com/98131995/225820562-1663601a-e9ce-44ce-971f-19ce5dd5d97f.png)<br>
![image](https://user-images.githubusercontent.com/98131995/225820651-3f46fe07-fea9-4fd8-baa4-d5c9a88e8b59.png)<br><br>
![Gridworld](https://user-images.githubusercontent.com/98131995/225821743-8408a9b1-7cd0-47ca-8331-98b6ec614c40.gif)<br>
![image](https://user-images.githubusercontent.com/98131995/225821148-2078b6c8-56e8-4c2d-a97b-c4260f9a8e4e.png)<br><br>

### Q1 - Value Iteration<br>
![image](https://user-images.githubusercontent.com/98131995/234208460-3b935328-b928-4ae6-965b-236b3c5eab03.png)<br><br>
<img src="https://user-images.githubusercontent.com/98131995/225823541-962e0a37-2eb1-4238-b90e-449f4ff059c3.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/225823063-b59e39e6-6d87-43bd-9411-614a8cef54f4.png" width=50% height=50%><br><br>
![image](https://user-images.githubusercontent.com/98131995/234208819-6f0c3801-d1a5-4f1e-8375-f2d63b2b27e3.png)<br><br>
<img src="https://user-images.githubusercontent.com/98131995/225823586-1c8830ba-c32c-46b3-8dc8-932b229c7008.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/225823878-678e17ab-ebd8-486c-9116-7525bae39a9c.png" width=50% height=50%><br><br>

### Q2 - Policies<br>
![image](https://user-images.githubusercontent.com/98131995/225827152-8412bec2-a79e-4cc7-b685-de2d4ba9a991.png)<br>
![image](https://user-images.githubusercontent.com/98131995/225827190-ea10f601-f7fb-466c-928d-f94d7c57c8c4.png)<br><br>

![image](https://user-images.githubusercontent.com/98131995/234256017-93338254-6bbb-4ae0-9d2f-781e0ec1d7a5.png)<br>
![image](https://user-images.githubusercontent.com/98131995/234258493-23174b5c-3d83-467a-8b74-14f99fc95722.png)<br>
<img src="https://user-images.githubusercontent.com/98131995/234256273-117899fe-fcbe-4fea-b1eb-6a6a06805fe7.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234256460-6dd13725-f64c-475c-a9bd-3ffa25b8b43b.png" width=50% height=50%><br><br>

![image](https://user-images.githubusercontent.com/98131995/234259307-6148dd0a-46f7-4589-a64b-7a6a4897f279.png)<br>
<img src="https://user-images.githubusercontent.com/98131995/234259492-637dad95-8ae4-481c-ad34-9d4b2f7be25f.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234259568-bf8ea6b6-dda3-42e4-9f56-e12314e5690e.png" width=50% height=50%><br><br>

![image](https://user-images.githubusercontent.com/98131995/234260076-2573c86a-d0eb-45b8-ab14-536437892031.png)<br>
<img src="https://user-images.githubusercontent.com/98131995/234260272-4fcec820-061c-4925-9fd2-7531cd6aad27.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234260413-c51b4b2f-e531-455e-ab87-76478f2240f5.png" width=50% height=50%><br><br>

![image](https://user-images.githubusercontent.com/98131995/234261727-4e7d3310-4ace-43ef-8f46-025ce2ae8471.png)<br>
<img src="https://user-images.githubusercontent.com/98131995/234261961-f6429765-36f9-4a6f-9b0c-f4aa14757605.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234262076-d67cbf91-fe18-4311-8331-47bc7fb011ba.png" width=50% height=50%><br><br>

![image](https://user-images.githubusercontent.com/98131995/234262918-701b1f1c-d18f-4516-b516-11c156e43c06.png)<br>
<img src="https://user-images.githubusercontent.com/98131995/234263175-90343a5d-a60f-49cb-9c0d-ae6c10df8a57.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234263352-ae098280-9a52-44a4-a896-f16b444a278e.png" width=50% height=50%><br><br>


### Q3 - Q-Learning<br>
![image](https://user-images.githubusercontent.com/98131995/225831054-75f893f9-0bd8-453d-bc90-3eae9b5f0a4c.png)<br>
![image](https://user-images.githubusercontent.com/98131995/225831218-9c9bc99a-d761-4984-a83f-58fd18cf4543.png)<br>
![image](https://user-images.githubusercontent.com/98131995/225831350-3035e5d2-bebc-404e-93ca-28e940d0f557.png)<br><br>

Q-Learner under manual control<br>
![manual q-learner](https://user-images.githubusercontent.com/98131995/234287237-b5827fc4-7dfb-448e-914a-9ea16bc015e0.gif)


### Q4 - Epsilon Greedy<br>
![image](https://user-images.githubusercontent.com/98131995/225831658-98a4d8db-38a4-4e44-b2f6-32497a64a2b4.png)<br><br>

Epsilon = 0.3 (balanced)<br>
<img src="https://user-images.githubusercontent.com/98131995/234271963-d79d1787-9333-49c1-a237-309220805888.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234272183-ab5d0e32-1415-4272-9b86-d8eb513a10d1.png" width=50% height=50%><br><br>

Epsilon = 0.1 (exploitation)<br>
<img src="https://user-images.githubusercontent.com/98131995/234273363-78f9a376-1b17-494e-aa98-264a45467898.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234273463-146fc8e8-5ea4-4525-9a28-6d844396317d.png" width=50% height=50%><br><br>

Epsilon = 0.9 (exploration)<br>
<img src="https://user-images.githubusercontent.com/98131995/234275479-c2b610c6-1869-4455-bfc3-9310599b920d.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/234275607-6a720da9-7418-4867-a7c0-ba6c4f0228d0.png" width=50% height=50%><br><br>

### Q5 - Q-Learning and Pacman<br>
After 10 training sessions:<br>
![image](https://user-images.githubusercontent.com/98131995/225833590-366f36d2-347e-44dd-a814-ed755c4eb36c.png)<br><br>
After 2000 training sessions:<br>
![image](https://user-images.githubusercontent.com/98131995/225833793-96c1a804-80f3-4fdb-8915-691b30bcbc1c.png)<br><br>

### Q6 - Approximate Q-Learning<br>
![image](https://user-images.githubusercontent.com/98131995/225834168-fc3cad95-78d5-4ba3-999f-b7cd45d17e3a.png)<br><br>
![Approximate Q-Learning](https://user-images.githubusercontent.com/98131995/225861305-789c83dc-0668-4974-81bf-2072496591c6.gif)<br><br>
<img src="https://user-images.githubusercontent.com/98131995/225857647-88cfde9d-d790-40c1-9cf6-89c619a0a635.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/225857867-f528aa0b-ca2f-4d51-a3cf-bcdd37de9346.png" width=50% height=50%><br>
<img src="https://user-images.githubusercontent.com/98131995/225858011-93c22b52-2637-4e0a-9452-463d497e0487.png" width=50% height=50%><img src="https://user-images.githubusercontent.com/98131995/225859558-b48f1093-fd35-4f9d-9fea-a4a498dadd21.png" width=50% height=50%><br><br>
![image](https://user-images.githubusercontent.com/98131995/225859892-6d5a91a1-313f-411e-95bd-3ed0aec0ee39.png)<br><br>

